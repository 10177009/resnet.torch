{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'cunn'\n",
    "require 'cudnn'\n",
    "createModel = require('models/tinydarknet_narrow')\n",
    "require 'utils/DistanceRatioCriterion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Convolution = cudnn.SpatialConvolution\n",
    "Avg = cudnn.SpatialAveragePooling\n",
    "ReLU = cudnn.ReLU\n",
    "Max = nn.SpatialMaxPooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " | TinyDarknet is created\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "print(' | TinyDarknet is created')\n",
    "\n",
    "-- The SimpleNet model\n",
    "model:add(Convolution(3,16,3,3,1,1,1,1))\n",
    "model:add(ReLU())\n",
    "model:add(Max(2,2,2,2,0,0))\n",
    "\n",
    "model:add(Convolution(16,32,3,3,1,1,1,1))\n",
    "model:add(ReLU())\n",
    "model:add(Max(2,2,2,2,0,0))\n",
    "\n",
    "model:add(Convolution(32,16,1,1,1,1,0,0))\n",
    "model:add(ReLU())\n",
    "model:add(Convolution(16,64,3,3,1,1,1,1))\n",
    "model:add(ReLU())\n",
    "model:add(Max(2,2,2,2,0,0))\n",
    "\n",
    "model:add(Convolution(64,16,1,1,1,1,0,0))\n",
    "model:add(ReLU())\n",
    "model:add(Convolution(16,128,3,3,1,1,1,1))\n",
    "model:add(ReLU())\n",
    "model:add(Max(2,2,2,2,0,0))\n",
    "\n",
    "model:add(Convolution(128,32,1,1,1,1,0,0))\n",
    "model:add(ReLU())\n",
    "model:add(Convolution(32,256,3,3,1,1,1,1))\n",
    "model:add(ReLU())\n",
    "model:add(Avg(14,14,1,1))\n",
    "\n",
    "model:add(nn.View(256):setNumInputDims(3))\n",
    "model:add(nn.Linear(256, 10))\n",
    "\n",
    "local function ConvInit(name)\n",
    "    for k,v in pairs(model:findModules(name)) do\n",
    "        local n = v.kW*v.kH*v.nOutputPlane\n",
    "        v.weight:normal(0,math.sqrt(2/n))\n",
    "        if cudnn.version >= 4000 then\n",
    "            v.bias = nil\n",
    "            v.gradBias = nil\n",
    "        else\n",
    "            v.bias:zero()\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "ConvInit('cudnn.SpatialConvolution')\n",
    "ConvInit('nn.SpatialConvolution')\n",
    "for k,v in pairs(model:findModules('nn.Linear')) do\n",
    "    v.bias:zero()\n",
    "end\n",
    "model:cuda()\n",
    "model:get(1).gradInput = nil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Init a siammese network with given models\n",
    "\n",
    "require 'nn'\n",
    "require 'cunn'\n",
    "require 'cudnn'\n",
    "require 'nnlr'\n",
    "require \"nnx\"\n",
    "require \"inn\"\n",
    "require 'nngraph'\n",
    "require 'utils/DistanceRatioCriterion'\n",
    "\n",
    "inn.utils = require 'inn.utils'\n",
    "local utils = require \"utils\"\n",
    "\n",
    "M = {}\n",
    "\n",
    "function M.setup(model)\n",
    "    local model = model\n",
    "\n",
    "    -- First remove any DataParallelTable\n",
    "    if torch.type(model) == 'nn.DataParallelTable' then\n",
    "        model = model:get(1)\n",
    "    end\n",
    "\n",
    "    -- For resetting the classifier when fine-tuning on a different Dataset\n",
    "\n",
    "    local orig = model:get(#model.modules)\n",
    "    assert(torch.type(orig) == 'nn.Linear',\n",
    "         'expected last layer to be fully connected')\n",
    "\n",
    "    local linear\n",
    "\n",
    "    linear = nn.Linear(orig.weight:size(2), 256)\n",
    "    linear.bias:zero()\n",
    "    model:remove(#model.modules)\n",
    "    model:add(linear:cuda())\n",
    "\n",
    "    -- Set Triplet Net\n",
    "    -- The siamese model\n",
    "    nngraph.setDebug(true)\n",
    "    -- Annotate nodes with local variable names\n",
    "    nngraph.annotateNodes()\n",
    "\n",
    "    local inputs = {}\n",
    "    inputs[1] = nn.Identity()()\n",
    "    inputs[2] = nn.Identity()()\n",
    "    inputs[3] = nn.Identity()()\n",
    "\n",
    "    local embeddings = {}\n",
    "    embeddings[1] = model(inputs[1])\n",
    "    embeddings[2] = model:clone('weight','bias', 'gradWeight','gradBias')(inputs[2])\n",
    "    embeddings[3] = model:clone('weight','bias', 'gradWeight','gradBias')(inputs[3])\n",
    "\n",
    "    local dists = {}\n",
    "    dists[1] = nn.PairwiseDistance(2):clone()({embeddings[1], embeddings[2]}) --L2 pairwise distance\n",
    "    dists[2] = nn.PairwiseDistance(2):clone()({embeddings[1], embeddings[3]}) --L2 pairwise distance\n",
    "\n",
    "    local model_triplet = nn.gModule(inputs, {dists[1], dists[2]}):cuda()\n",
    "    model_triplet.name = 'triplet_net'\n",
    "\n",
    "    -- Set the CUDNN flags\n",
    "    cudnn.fastest = true\n",
    "    cudnn.benchmark = true\n",
    "\n",
    "    -- set criterion\n",
    "    local criterion\n",
    "    criterion = nn.DistanceRatioCriterion(margin):cuda()\n",
    "    return model_triplet, criterion\n",
    "end\n",
    "\n",
    "function M.shareGradInput(model)\n",
    "    local function sharingKey(m)\n",
    "        local key = torch.type(m)\n",
    "        if m.__shareGradInputKey then\n",
    "            key = key .. ':' .. m.__shareGradInputKey\n",
    "        end\n",
    "        return key\n",
    "    end\n",
    "\n",
    "    -- Share gradInput for memory efficient backprop\n",
    "    local cache = {}\n",
    "    model:apply(function(m)\n",
    "        local moduleType = torch.type(m)\n",
    "        if torch.isTensor(m.gradInput) and moduleType ~= 'nn.ConcatTable' then\n",
    "            local key = sharingKey(m)\n",
    "            if cache[key] == nil then\n",
    "                cache[key] = torch.CudaStorage(1)\n",
    "            end\n",
    "            m.gradInput = torch.CudaTensor(cache[key], 1, 0)\n",
    "        end\n",
    "    end)\n",
    "    for i, m in ipairs(model:findModules('nn.ConcatTable')) do\n",
    "        if cache[i % 2] == nil then\n",
    "            cache[i % 2] = torch.CudaStorage(1)\n",
    "        end\n",
    "        m.gradInput = torch.CudaTensor(cache[i % 2], 1, 0)\n",
    "    end\n",
    "end\n",
    "\n",
    "return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, criterion = M.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = {torch.rand(24,3,224,224),torch.rand(24,3,224,224),torch.rand(24,3,224,224)}\n",
    "input_cuda = {torch.CudaTensor(),torch.CudaTensor(),torch.CudaTensor()}\n",
    "input_cuda[1]:resize(input[1]:size()):copy(input[1])\n",
    "input_cuda[2]:resize(input[2]:size()):copy(input[2])\n",
    "input_cuda[3]:resize(input[3]:size()):copy(input[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"output = model:forward(input_cuda)...\"]:1: attempt to call method 'forward' (a nil value)\nstack traceback:\n\t[string \"output = model:forward(input_cuda)...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/eightbit/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"output = model:forward(input_cuda)...\"]:1: attempt to call method 'forward' (a nil value)\nstack traceback:\n\t[string \"output = model:forward(input_cuda)...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/eightbit/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670"
     ]
    }
   ],
   "source": [
    "output = model:forward(input_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.DistanceRatioCriterion():cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 48\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "bad argument #2 to '?' (too many indices provided)\nstack traceback:\n\t[C]: at 0x7f396c6679a0\n\t[C]: in function '__index'\n\t./utils/DistanceRatioCriterion.lua:15: in function 'createTarget'\n\t./utils/DistanceRatioCriterion.lua:21: in function 'f'\n\t[string \"local f = function() return criterion:forward...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/eightbit/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "bad argument #2 to '?' (too many indices provided)\nstack traceback:\n\t[C]: at 0x7f396c6679a0\n\t[C]: in function '__index'\n\t./utils/DistanceRatioCriterion.lua:15: in function 'createTarget'\n\t./utils/DistanceRatioCriterion.lua:21: in function 'f'\n\t[string \"local f = function() return criterion:forward...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/eightbit/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t.../eightbit/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/eightbit/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670"
     ]
    }
   ],
   "source": [
    "criterion:forward(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
